1.UDP

1.1. 发送H.264裸流至组播地址
注：组播地址指的范围是224.0.0.0—239.255.255.255
下面命令实现了发送H.264裸流“chunwan.h264”至地址udp://233.233.233.223:6666
注1：-re一定要加，代表按照帧率发送，否则ffmpeg会一股脑地按最高的效率发送数据。
注2：-vcodec copy要加，否则ffmpeg会重新编码输入的H.264裸流。
ffmpeg -re -i h288_w512.h264 -vcodec copy -f h264 udp://233.233.233.223:6666

1.2. 播放承载H.264裸流的UDP
ffplay -f h264 udp://233.233.233.223:6666
注：需要使用-f说明数据类型是H.264
播放的时候可以加一些参数，比如-max_delay，下面命令将-max_delay设置为100ms：
ffplay -max_delay 100000 -f h264 udp://233.233.233.223:6666

1.3. 发送MPEG2裸流至组播地址
下面的命令实现了读取本地摄像头的数据，编码为MPEG2，发送至地址udp://233.233.233.223:6666。
ffmpeg -re -i h288_w512.h264 -vcodec mpeg2video -f mpeg2video udp://233.233.233.223:6666

1.4.  播放MPEG2裸流
指定-vcodec为mpeg2video即可。
ffplay -vcodec mpeg2video udp://233.233.233.223:6666

==========================================================================================
2.RTP

2.1. 发送H.264裸流至组播地址。
下面命令实现了发送H.264裸流“chunwan.h264”至地址rtp://233.233.233.223:6666
ffmpeg -re -i h288_w512.h264 -vcodec copy -f rtp rtp://233.233.233.223:6666>test.sdp
注1：-re一定要加，代表按照帧率发送，否则ffmpeg会一股脑地按最高的效率发送数据。
注2：-vcodec copy要加，否则ffmpeg会重新编码输入的H.264裸流。
注3：最右边的“>test.sdp”用于将ffmpeg的输出信息存储下来形成一个sdp文件。该文件用于RTP的接收。当不加“>test.sdp”的时候，ffmpeg会直接把sdp信息输出到控制台。
将该信息复制出来保存成一个后缀是.sdp文本文件，也是可以用来接收该RTP流的。加上“>test.sdp”后，可以直接把这些sdp信息保存成文本。

2.2. 播放承载H.264裸流的RTP。
ffplay test.sdp -protocol_whitelist file,udp,rtp
==========================================================================================
3.RTMP
需要先安装nginx 并且要支持rtmp (nginx.conf文件在同目录里)
https://github.com/arut/nginx-rtmp-module
http://blog.csdn.net/xdwyyan/article/details/43198985
http://blog.csdn.net/redstarofsleep/article/details/45092147

./configure --prefix=/usr/local/nginx --add-module=/root/www/soft/nginx-rtmp-module-master  --with-http_ssl_module
make
make install
vim /usr/local/nginx/conf/nginx.conf
/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf

3.1. 发送H.264裸流至RTMP服务器

ffmpeg -re -i h288_w512.h264 -vcodec copy -f flv rtmp://localhost:1935/myapp/test1
ffplay "rtmp://localhost/myapp/test1 live=1"

ffmpeg -re -i "h288_w512.mp4" -vcodec libx264 -vprofile baseline -acodec aac  -ar 44100 -strict -2 -ac 1 -f flv -s 288x512 -q 10 rtmp://localhost:1935/hls/test2
ffplay "rtmp://localhost/hls/test2 live=1"
==========================================================================================
4.测延时

4.1.测延时

测延时有一种方式，即一路播放发送端视频，另一路播放流媒体接收下来的流。
播放发送端的流有2种方式：FFmpeg和FFplay。
通过FFplay播放是一种众所周知的方法，例如：
windows:
ffplay -f dshow -i video="Integrated Camera"
linux:
ffplay -f video4linux2 -i /dev/video0
即可播放本地名称为“Integrated Camera”的摄像头。

FFmpeg也可以进行播放，通过指定参数“-f sdl”即可。例如：
ffmpeg -re -i "h288_w512.h264" -pix_fmt yuv420p  -f sdl xxxx.yuv -vcodec copy -f flv rtmp://localhost:1935/hls/test3
ffplay "rtmp://localhost/hls/test3 live=1"


就可以一边通过SDL播放视频，一边发送视频流至RTMP服务器。
注1：sdl后面指定的xxxx.yuv并不会输出出来。
注2：FFmpeg本身是可以指定多个输出的。本命令相当于指定了两个输出。
播放接收端的方法前文已经提及，在此不再详述。


==========================================================================================
